rownames(tobind) <- (nrow(newdf)+1):(nrow(newdf)+nrow(tobind))
newdf2 <- rbind(newdf, tobind)
nrow(newdf2[newdf2$Category == "COMICS",])
parent <- newdf2[newdf2$Category == "COMICS",]
addpar <- sample(rownames(parent), nrow(parent)*19/20)
tobind <- newdf2[addpar,]
rownames(tobind) <- (nrow(newdf2)+1):(nrow(newdf2)+nrow(tobind))
newdf3 <- rbind(newdf2, tobind)
nrow(newdf3[newdf3$Category == "COMICS",])
setwd("C:/Users/ishan/Documents")
getwd()
fvm3 <- read.csv("newbeauty.csv")
str(fvm3)
###COMICS 220
parent <- newdf[newdf$Category == "COMICS",]
addpar <- sample(rownames(parent), nrow(parent)*19/20)
tobind <- newdf[addpar,]
rownames(tobind) <- (nrow(newdf)+1):(nrow(newdf)+nrow(tobind))
newdf2 <- rbind(newdf, tobind)
nrow(newdf2[newdf2$Category == "COMICS",])
parent <- newdf2[newdf2$Category == "COMICS",]
addpar <- sample(rownames(parent), nrow(parent)*19/20)
tobind <- newdf2[addpar,]
rownames(tobind) <- (nrow(newdf2)+1):(nrow(newdf2)+nrow(tobind))
newdf3 <- rbind(newdf2, tobind)
nrow(newdf3[newdf3$Category == "COMICS",])
setwd("C:/Users/ishan/Documents")
getwd()
fvm3 <- read.csv("newbeauty.csv")
str(fvm3)
###COMICS 220
parent <- newdf[newdf$Category == "COMICS",]
addpar <- sample(rownames(parent), nrow(parent)*19/20)
tobind <- newdf[addpar,]
rownames(tobind) <- (nrow(newdf)+1):(nrow(newdf)+nrow(tobind))
newdf2 <- rbind(newdf, tobind)
nrow(newdf2[newdf2$Category == "COMICS",])
parent <- newdf2[newdf2$Category == "COMICS",]
addpar <- sample(rownames(parent), nrow(parent)*19/20)
tobind <- newdf2[addpar,]
rownames(tobind) <- (nrow(newdf2)+1):(nrow(newdf2)+nrow(tobind))
newdf3 <- rbind(newdf2, tobind)
nrow(newdf3[newdf3$Category == "COMICS",])
write.csv(newdf, "newcomics.csv", row.names = F)
newcomics <- read.csv("~/newcomics.csv", header=FALSE)
View(newcomics)
setwd("C:/Users/ishan/Documents")
getwd()
fvm3 <- read.csv("newcomics.csv")
str(fvm3)
###EVENTS 169
parent <- newdf[newdf$Category == "EVENTS",]
addpar <- sample(rownames(parent), nrow(parent)*19/20)
tobind <- newdf[addpar,]
rownames(tobind) <- (nrow(newdf)+1):(nrow(newdf)+nrow(tobind))
newdf2 <- rbind(newdf, tobind)
nrow(newdf2[newdf2$Category == "EVENTS",])
parent <- newdf2[newdf2$Category == "EVENTS",]
addpar <- sample(rownames(parent), nrow(parent)*19/20)
tobind <- newdf2[addpar,]
rownames(tobind) <- (nrow(newdf2)+1):(nrow(newdf2)+nrow(tobind))
newdf3 <- rbind(newdf2, tobind)
nrow(newdf3[newdf3$Category == "EVENTS",])
setwd("C:/Users/ishan/Documents")
getwd()
fvm3 <- read.csv("newcomics.csv")
str(fvm3)
###EVENTS 169
parent <- newdf[newdf$Category == "EVENTS",]
addpar <- sample(rownames(parent), nrow(parent)*19/20)
tobind <- newdf[addpar,]
rownames(tobind) <- (nrow(newdf)+1):(nrow(newdf)+nrow(tobind))
newdf2 <- rbind(newdf, tobind)
nrow(newdf2[newdf2$Category == "EVENTS",])
parent <- newdf2[newdf2$Category == "EVENTS",]
addpar <- sample(rownames(parent), nrow(parent)*19/20)
tobind <- newdf2[addpar,]
rownames(tobind) <- (nrow(newdf2)+1):(nrow(newdf2)+nrow(tobind))
newdf3 <- rbind(newdf2, tobind)
nrow(newdf3[newdf3$Category == "EVENTS",])
write.csv(newdf, "newevents.csv", row.names = F)
newevents <- read.csv("~/newevents.csv", header=FALSE)
View(newevents)
nrow(newdf3[newdf3$Category == "BEAUTY",])
qchisq(0.05,19.lower.tail=FALSE)
qchisq(0.05,19,lower.tail=FALSE)
?binom.test
binom(4,6,p=.5)
binom.test(4,6,p=.5)
binom.test(4,6,p=.5)+binom.test(5,6,p=.5)
binom.test(5,6,p=.5)
binom.test(6,6,p=.5)
friday <- c(4,-64,3,-1,1,7)
mean(friday)
sd(friday)
t.test(friday)
friday2 <- c(13,12,14,10,4,12)
friday1 <- c(9,76,11,11,3,5)
friday2 <- c(13,12,14,10,4,12)
diff_friday <- c(4,-64,3,-1,1,7)
t.test(friday1,friday2)
t.test(friday1,friday2,paired=TRUE)
pt(.77483,df=5)
pt(-.77483,df=5)
pt(-.77483,df=5,lower.tail=FALSE)
################################### CODE FROM PROF #####################################################
##UMP for poisson example
lambda_0=5
n=10
##if you don't know qpois, type ? qpois
c=qpois(0.95, lambda=lambda_0*n) #this is the smaller integer x such that P(X ≤ x) ≥ 0.95.
p=(0.05-ppois(c,lambda=lambda_0*n,lower.tail=F))/dpois(c,lambda=(lambda_0*n))
##check whether this is 0.05
ppois(c,lambda=lambda_0*n,lower.tail=F) +p*dpois(c,lambda=(lambda_0*n))
#this is c
c
##this is p
p
##Here we perform a simulation start to show the type I error of this test
##we do M simulations
M=100000
##we record the number of timkes we make type I error
num_type_I_errors=0
for(i in 1:M){
##if you fit the seed below, you will get the same result each time
##set.seed(i)
##generate n Poisson observations with rate 5 (from null hypothesis)
x=rpois(n=10,lambda=5) ##you can also tpye rpois(10,5)
##compute whether I made type I error in this simulation
if(sum(x)>c){
num_type_I_errors=num_type_I_errors+1
}else if(sum(x)==c){
z=rbinom(n=1,size=1,prob=p)
if(z==1){
num_type_I_errors=num_type_I_errors+1
}
}
}
num_type_I_errors/M ##type I error rate
?pbinom
pbinom(1/2,8)
?qbinom
?qpois
c=qbinom(0.95,size = 8,prob = 1/2)
## Binomial Distribution
n=8
m=qbinom(0.95,size = 8,prob = 1/2)
q=(.05-pbinom(m,size=8,prob=1/2,lower.tail=FALSE))/dbinom(m,size=8,prob=1/2)
pbinom(m,size=8,prob=1/2,lower.tail=FALSE) + q*dbinom(m,size=8,prob=1/2)
m=qbinom(0.95,size = 8,prob = 1/2)
q=(.05-pbinom(m,size=8,prob=1/2,lower.tail=FALSE))/dbinom(m,size=8,prob=1/2)
m
p
q
n=10
##if you don't know qpois, type ? qpois
c=qpois(0.95, lambda=lambda_0*n) #this is the smaller integer x such that P(X ≤ x) ≥ 0.95.
p=(0.05-ppois(c,lambda=lambda_0*n,lower.tail=F))/dpois(c,lambda=(lambda_0*n))
##check whether this is 0.05
ppois(c,lambda=lambda_0*n,lower.tail=F) +p*dpois(c,lambda=(lambda_0*n))
#this is c
c
##this is p
p
?rpois
?rbinom
# 4b
N=1000
##we record the number of timkes we make type I error
num_type_I_errors=0
for(i in 1:N){
##if you fit the seed below, you will get the same result each time
##set.seed(i)
##generate n Binomial observations with prob 1/2 (from null hypothesis)
x=rbinom(n=8,prob=1/2)
##compute whether I made type I error in this simulation
if(sum(x)>m){
num_type_I_errors=num_type_I_errors+1
}else if(sum(x)==m){
z=rbinom(n=1,size=1,prob=q)
if(z==1){
num_type_I_errors=num_type_I_errors+1
}
}
}
num_type_I_errors/N ##type I error rate
# 4b
N=1000
##we record the number of timkes we make type I error
num_type_I_errors=0
for(i in 1:N){
##if you fit the seed below, you will get the same result each time
##set.seed(i)
##generate n Binomial observations with prob 1/2 (from null hypothesis)
x=rbinom(n=6,size=8,prob=1/2)
##compute whether I made type I error in this simulation
if(sum(x)>m){
num_type_I_errors=num_type_I_errors+1
}else if(sum(x)==m){
z=rbinom(n=1,size=1,prob=q)
if(z==1){
num_type_I_errors=num_type_I_errors+1
}
}
}
num_type_I_errors/N ##type I error rate
# 4b
N=1000
##we record the number of timkes we make type I error
num_type_I_errors=0
for(i in 1:N){
##if you fit the seed below, you will get the same result each time
##set.seed(i)
##generate n Binomial observations with prob 1/2 (from null hypothesis)
x=rbinom(n=8,size=8,prob=1/2)
##compute whether I made type I error in this simulation
if(sum(x)>m){
num_type_I_errors=num_type_I_errors+1
}else if(sum(x)==m){
z=rbinom(n=1,size=1,prob=q)
if(z==1){
num_type_I_errors=num_type_I_errors+1
}
}
}
num_type_I_errors/N ##type I error rate
# 4b
N=1000
##we record the number of timkes we make type I error
num_type_I_errors=0
for(i in 1:N){
##if you fit the seed below, you will get the same result each time
##set.seed(i)
##generate n Binomial observations with prob 1/2 (from null hypothesis)
x=rbinom(n=8,size=8,prob=1/2)
##compute whether I made type I error in this simulation
if(sum(x)>m){
num_type_I_errors=num_type_I_errors+1
}else if(sum(x)==m){
z=rbinom(n=1,size=1,prob=p)
if(z==1){
num_type_I_errors=num_type_I_errors+1
}
}
}
num_type_I_errors/N ##type I error rate
## Binomial Distribution
n=8
m=qbinom(0.95,size = 8,prob = 1/2)
q=(.05-pbinom(m,size=8,prob=1/2,lower.tail=FALSE))/dbinom(m,size=8,prob=1/2)
pbinom(m,size=8,prob=1/2,lower.tail=FALSE) + q*dbinom(m,size=8,prob=1/2)
# this is m
m
# this is q
q
num_type_I_errors=0
for(i in 1:N){
##if you fit the seed below, you will get the same result each time
##set.seed(i)
##generate n Binomial observations with prob 1/2 (from null hypothesis)
x=rbinom(n=8,size=8,prob=1/2)
##compute whether I made type I error in this simulation
if(sum(x)>m){
num_type_I_errors=num_type_I_errors+1
}else if(sum(x)==m){
z=rbinom(n=1,size=1,prob=p)
if(z==1){
num_type_I_errors=num_type_I_errors+1
}
}
}
num_type_I_errors/N ##type I error rate
# 4b
N=1000
##we record the number of timkes we make type I error
num_type_I_errors=0
for(i in 1:N){
##if you fit the seed below, you will get the same result each time
##set.seed(i)
##generate n Binomial observations with prob 1/2 (from null hypothesis)
x=rbinom(n=8,size=8,prob=1/2)
##compute whether I made type I error in this simulation
if(sum(x)>m){
num_type_I_errors=num_type_I_errors+1
}else if(sum(x)==m){
z=rbinom(n=1,size=1,prob=p)
if(z==1){
num_type_I_errors=num_type_I_errors+1
}
}
}
num_type_I_errors/N ##type I error rate
p
##we record the number of timkes we make type I error
num_type_I_errors=0
for(i in 1:N){
##if you fit the seed below, you will get the same result each time
##set.seed(i)
##generate n Binomial observations with prob 1/2 (from null hypothesis)
x=rbinom(n=8,size=8,prob=1/2)
##compute whether I made type I error in this simulation
if(sum(x)>m){
num_type_I_errors=num_type_I_errors+1
}else if(sum(x)==m){
z=rbinom(n=1,size=1,prob=q)
if(z==1){
num_type_I_errors=num_type_I_errors+1
}
}
}
num_type_I_errors/N ##type I error rate
num_type_I_errors=0
for(i in 1:N){
##if you fit the seed below, you will get the same result each time
##set.seed(i)
##generate n Binomial observations with prob 1/2 (from null hypothesis)
x=rbinom(n=8,size=8,prob=1/2)
##compute whether I made type I error in this simulation
if(sum(x)>m){
print(sum(x))
num_type_I_errors=num_type_I_errors+1
}else if(sum(x)==m){
z=rbinom(n=1,size=1,prob=q)
if(z==1){
num_type_I_errors=num_type_I_errors+1
# 4b
N=1000
pnorm(1.195)
pnorm(1.29)
knitr::opts_chunk$set(echo = TRUE)
data <- data.frame(factor(part) = rep(1:10,each=9), factor(inspector) = rep(1:3,times=10,each=3), "Value" = c(37,38,37,41,41,40,41,42,41,
mod2 <- aov(Value~as.factor(Part.Number)*as.factor(Inspector.Number),data=data)
part <- rep(1:10, each=9)
inspector <- rep(1:3, times=10, each=3)
data <- data.frame(factor(part), factor(inspector), y=
c(37,38,37,41,41,40,41,42,41,
42,41,43,42,42,42,43,42,43,
30,31,31,31,31,31,29,30,28,
42,43,42,43,43,43,42,42,42,
28,30,29,29,30,29,31,29,29,
42,42,43,45,45,45,44,46,45,
25,26,27,28,28,30,29,27,27,
40,40,40,43,42,42,43,43,41,
25,25,25,27,29,28,26,26,26,
35,34,34,35,35,34,35,34,35))
print(head(data,n=10))
part <- rep(1:10, each=9)
inspector <- rep(1:3, times=10, each=3)
data <- data.frame(factor(part), factor(inspector), Value=
c(37,38,37,41,41,40,41,42,41,
42,41,43,42,42,42,43,42,43,
30,31,31,31,31,31,29,30,28,
42,43,42,43,43,43,42,42,42,
28,30,29,29,30,29,31,29,29,
42,42,43,45,45,45,44,46,45,
25,26,27,28,28,30,29,27,27,
40,40,40,43,42,42,43,43,41,
25,25,25,27,29,28,26,26,26,
35,34,34,35,35,34,35,34,35))
print(head(data,n=10))
mod1<- aov(Value~as.factor(Part.Number)+as.factor(Inspector.Number),data=data)
mod1<- aov(Value~as.factor(part)+as.factor(inspector),data=data)
anova(mod1)
mod2 <- aov(Value~as.factor(part)*as.factor(inspector),data=data)
anova(mod2)
model <- aov(Value~as.factor(part)*as.factor(inspector),data=data)
anova(model)
model <- aov(Value~as.factor(part)*as.factor(inspector),data=data)
anova(model)
?aov
F1 = 437.33/2.7
F2 = 19.63/2.7
F3 = 2.7/0.51
randomModel <- data.table
F1 = 437.33/2.7
F2 = 19.63/2.7
F3 = 2.7/0.51
# randomModel <- data.table
?data.table
pf(F1,9,18)
pf(F1,9,18,lower.tail=FALSE)
F1 = 437.33/2.7
F2 = 19.63/2.7
F3 = 2.7/0.51
randomModel <- table(Df = c(9,2,18,60), SumSq = c(3936.0,39.3,48.5,30.7), MeanSq = c(437.33,19.63,2.70,0.51), FValue = c(F1,F2,F3), Pval = c(pf(F1,9,18,lower.tail = FALSE),pf(F2,2,18,lower.tail = FALSE),pf(F3,18,60,lower.tail= FALSE)))
F1 = 437.33/2.7
F2 = 19.63/2.7
F3 = 2.7/0.51
randomModel <- data.frame(Df = c(9,2,18,60), SumSq = c(3936.0,39.3,48.5,30.7), MeanSq = c(437.33,19.63,2.70,0.51), FValue = c(F1,F2,F3), Pval = c(pf(F1,9,18,lower.tail = FALSE),pf(F2,2,18,lower.tail = FALSE),pf(F3,18,60,lower.tail= FALSE)))
F1 = 437.33/2.7
F2 = 19.63/2.7
F3 = 2.7/0.51
randomModel <- data.frame(Df = c(9,2,18,60), SumSq = c(3936.0,39.3,48.5,30.7), MeanSq = c(437.33,19.63,2.70,0.51), FValue = c(F1,F2,F3,NA), Pval = c(pf(F1,9,18,lower.tail = FALSE),pf(F2,2,18,lower.tail = FALSE),pf(F3,18,60,lower.tail= FALSE),NA))
F1 = 437.33/2.7
F2 = 19.63/2.7
F3 = 2.7/0.51
randomModel <- data.frame(Df = c(9,2,18,60), SumSq = c(3936.0,39.3,48.5,30.7), MeanSq = c(437.33,19.63,2.70,0.51), FValue = c(F1,F2,F3,NA), Pval = c(pf(F1,9,18,lower.tail = FALSE),pf(F2,2,18,lower.tail = FALSE),pf(F3,18,60,lower.tail= FALSE),NA))
print(randomModel)
F1 = 437.33/2.7
F2 = 19.63/2.7
F3 = 2.7/0.51
randomModel <- data.frame(Source = c(part,inspector,interaction,error), Df = c(9,2,18,60), SumSq = c(3936.0,39.3,48.5,30.7), MeanSq = c(437.33,19.63,2.70,0.51), FValue = c(F1,F2,F3,NA), Pval = c(pf(F1,9,18,lower.tail = FALSE),pf(F2,2,18,lower.tail = FALSE),pf(F3,18,60,lower.tail= FALSE),NA))
F1 = 437.33/2.7
F2 = 19.63/2.7
F3 = 2.7/0.51
randomModel <- data.frame(Source = c("part","inspector","interaction","residuals"), Df = c(9,2,18,60), SumSq = c(3936.0,39.3,48.5,30.7), MeanSq = c(437.33,19.63,2.70,0.51), FValue = c(F1,F2,F3,NA), Pval = c(pf(F1,9,18,lower.tail = FALSE),pf(F2,2,18,lower.tail = FALSE),pf(F3,18,60,lower.tail= FALSE),NA))
print(randomModel)
F1 = 437.33/2.7
F2 = 19.63/2.7
F3 = 2.7/0.51
randomModel <- data.frame(Source = c("factor.part","factor.inspector","interaction","residuals"), Df = c(9,2,18,60), SumSq = c(3936.0,39.3,48.5,30.7), MeanSq = c(437.33,19.63,2.70,0.51), FValue = c(F1,F2,F3,NA), Pval = c(pf(F1,9,18,lower.tail = FALSE),pf(F2,2,18,lower.tail = FALSE),pf(F3,18,60,lower.tail= FALSE),NA))
print(randomModel)
(sigma-TB-Hat)^2 <- (2.70-0.51)/3
sigTBHatSquare <- (2.70-0.51)/3
sigBHatSquare <- (19.64-2.70)/(3*3)
sigTHatSquare <- (437.33-2.70)/(10*3)
sigHatSquare <- 0.51
sigHatSquare <- 0.51
sigTHatSquare <- (437.33-2.70)/(10*3)
sigBHatSquare <- (19.64-2.70)/(3*3)
sigTBHatSquare <- (2.70-0.51)/3
sigHatSquare
sigTHatSquare
sigBHatSquare
sigTBHatSquare
437.33-2.7
434.63/30
sigHatSquare <- 0.51
sigTHatSquare <- (437.33-2.70)/(3*3)
sigBHatSquare <- (19.64-2.70)/(10*3)
sigTBHatSquare <- (2.70-0.51)/3
sigHatSquare
sigTHatSquare
sigBHatSquare
sigTBHatSquare
sigHatSquare <- 0.51
sigTHatSquare <- (437.33-2.70)/(3*3)
sigBHatSquare <- (19.63-2.70)/(10*3)
sigTBHatSquare <- (2.70-0.51)/3
sigHatSquare
sigTHatSquare
sigBHatSquare
sigTBHatSquare
install.packages("datasets")
install.packages("datasets")
install.packages("datasets")
install.packages("datasets")
install.packages("datasets")
install.packages("datasets")
install.packages("datasets")
help("summary.lm")
knitr::opts_chunk$set(echo = TRUE)
x <- c(1,2,3,4,5)
y <- c(1,2,1.3,3.75,2.25)
xbar = mean(x)
ybar = mean(y)
Sxx = sum((x-xbar)^2)
Syy = sum((y-ybar)^2)
Sxy = sum((x-xbar)*(y-ybar))
cat("xbar = ",xbar,"\n")
cat("ybar = ",ybar,"\n")
cat("Sxx = ",Sxx,"\n")
cat("Syy = ",Syy,"\n")
cat("Sxy = ",Sxy,"\n")
r = Sxy/sqrt(Sxx*Syy)
b1 = r*sqrt(Syy/Sxx)
b0 = ybar - b1*xbar
print(b1)
print(b0)
b1 = Sxy/Sxx
b0 = ybar - b1*x
print(b1)
print(b0)
b1 = Sxy/Sxx
b0 = ybar - b1*xbar
print(b1)
print(b0)
b1 = Sxy/Sxx
b0 = ybar - b1*xbar
r = Sxy/sqrt(Sxx*Syy)
print(b1)
print(b0)
print(r)
getwd()
setwd("/Users/ishan/Documents/College Year 2/Spring 2020/PSTAT 126/hw/hw 2)
"")
knitr::opts_chunk$set(echo = TRUE)
y <- c(16,5,10,15,13,22)
X <- X = matrix(c(1,1,1,1,1,1,4,1,2,3,3,4), ncol=2, byrow=FALSE)
y <- c(16,5,10,15,13,22)
X = matrix(c(1,1,1,1,1,1,4,1,2,3,3,4), ncol=2, byrow=FALSE)
X
b = solve(t(X)%*%X)%*%t(X)%*%y
b
H_matrix = X%*%solve(t(X)%*%X)%*%t(X)
H_matrix
divusa <- read.csv("divusa.csv")
getwd()
setwd("/Users/ishan/Documents/College Year 2/Spring 2020/PSTAT 126/pstat-126-proj")
winequality.red <- read.csv("~/College Year 2/Spring 2020/PSTAT 126/pstat-126-proj/winequality-red.csv")
View(winequality.red)
winequality.white <- read.csv("~/College Year 2/Spring 2020/PSTAT 126/pstat-126-proj/winequality-white.csv")
View(winequality.white)
knitr::opts_chunk$set(echo = TRUE)
white <- read.csv("winequality-white.csv")
pairs(white, main="Scatterplot Maatrix of White Wine Quality Data")
pairs(white, main="Scatterplot Maatrix of White Wine Quality Data")
pairs(white, main="Scatterplot Maatrix of White Wine Quality Data")
corr(white)
library(leaps)
corr(white)
cor(white)
